{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a corpus \n",
    "corpus=\"\"\"\n",
    "Hello Welcome to the world of AI. Here you will learn about the latest and most popular AI tools.\n",
    "You will also learn  how to use them in your projects\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nHello Welcome to the world of AI. Here you will learn about the latest and most popular AI tools.\\nYou will also learn  how to use them in your projects'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt_tab.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\nHello Welcome to the world of AI.',\n",
       " 'Here you will learn about the latest and most popular AI tools.',\n",
       " 'You will also learn  how to use them in your projects']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Tokenization\n",
    "## Paragraph --> sentence\n",
    "\n",
    "from nltk.tokenize import sent_tokenize\n",
    "sent_tokenize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello',\n",
       " 'Welcome',\n",
       " 'to',\n",
       " 'the',\n",
       " 'world',\n",
       " 'of',\n",
       " 'AI',\n",
       " '.',\n",
       " 'Here',\n",
       " 'you',\n",
       " 'will',\n",
       " 'learn',\n",
       " 'about',\n",
       " 'the',\n",
       " 'latest',\n",
       " 'and',\n",
       " 'most',\n",
       " 'popular',\n",
       " 'AI',\n",
       " 'tools',\n",
       " '.',\n",
       " 'You',\n",
       " 'will',\n",
       " 'also',\n",
       " 'learn',\n",
       " 'how',\n",
       " 'to',\n",
       " 'use',\n",
       " 'them',\n",
       " 'in',\n",
       " 'your',\n",
       " 'projects']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# paragraph --> words\n",
    "# Sentence --> words\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "word_tokenize(corpus)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello',\n",
       " 'Welcome',\n",
       " 'to',\n",
       " 'the',\n",
       " 'world',\n",
       " 'of',\n",
       " 'AI',\n",
       " '.',\n",
       " 'Here',\n",
       " 'you',\n",
       " 'will',\n",
       " 'learn',\n",
       " 'about',\n",
       " 'the',\n",
       " 'latest',\n",
       " 'and',\n",
       " 'most',\n",
       " 'popular',\n",
       " 'AI',\n",
       " 'tools',\n",
       " '.',\n",
       " 'You',\n",
       " 'will',\n",
       " 'also',\n",
       " 'learn',\n",
       " 'how',\n",
       " 'to',\n",
       " 'use',\n",
       " 'them',\n",
       " 'in',\n",
       " 'your',\n",
       " 'projects']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from  nltk.tokenize import wordpunct_tokenize\n",
    "wordpunct_tokenize(corpus)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello',\n",
       " 'Welcome',\n",
       " 'to',\n",
       " 'the',\n",
       " 'world',\n",
       " 'of',\n",
       " 'AI.',\n",
       " 'Here',\n",
       " 'you',\n",
       " 'will',\n",
       " 'learn',\n",
       " 'about',\n",
       " 'the',\n",
       " 'latest',\n",
       " 'and',\n",
       " 'most',\n",
       " 'popular',\n",
       " 'AI',\n",
       " 'tools.',\n",
       " 'You',\n",
       " 'will',\n",
       " 'also',\n",
       " 'learn',\n",
       " 'how',\n",
       " 'to',\n",
       " 'use',\n",
       " 'them',\n",
       " 'in',\n",
       " 'your',\n",
       " 'projects']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "tokenizer=TreebankWordTokenizer()\n",
    "tokenizer.tokenize(corpus)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
